---
title: "Big Tech Stock Prices"
subtitle: "An analysis of 14 Big Tech stocks from 2010 - 2020"
author: "Tech Titans"
format: 
  html:
    embed-resources: true
toc: true
execute:
  warning: false
  message: false
  results: hide 
  echo: false
editor: visual
jupyter: python3
---

## Abstract

The goal of this project is to understand the temporal behavior of Big Tech stocks that are actively traded on the NYSE. This analysis will show trends in the market to understand times when the market was on a downtrend (bear market) or in an uptrend (bull market). This will provide insight into times when investments should be made or when they should be pulled back. Investment analyses such as the aformentioned are extremely valuable to large finanacial institutions that aim to benefit from growth in the market. This is extremely important for those who place their hard earned dollar with these institutions as a means to save for retirement.

The analysis will consist of answering two key questions in a sequential manner: exploratory data analysis (EDA), data wrangling, and data visualization. This process is key to gaining insight from the data and allows for a clean platform that can used to train machine learning models.
```{python}
#| label: load-pkgs
#| message: false

# Importing the required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from scipy import stats


# Loading Data
stocks = pd.read_csv('data/big_tech_stock_prices.csv')
companies = pd.read_csv('data/big_tech_companies.csv')


```

## Introduction to the Dataset

The dataset used in this analysis was sourced from Tidy Tuesday; an open source conglomeration of data for visualization and machine learning. The dataset contains information on 14 different Big Tech companies's stock price and trading volume from 2010 to 2022 on the New York Stock Exchange. There are two .csv (comma seperated variable) files used, one called "big_tech_stock_prices.csv" and another called "big_tech_companies.csv". For simplicity, the files are renamed "stocks" and "companies", respectively. Stocks contains a majority of the information used in this analysis, including the daily low, high, open, and close prices, as well as trading volume. Low price represents the lowest price for the day while high price represents the opposite. Open price represents the price when the market opens at 9:30am ET, and close price represents the price when the market closes at 4pm ET. Trading volume represents the amount of stocks bought and sold that day; this metric is important for understanding the popularity of the stock.

The interest in this dataset was sparked by its potential to provide valuable insights into the stock market behavior of big tech companies. This enables a comprehensive examination of stock market trends, facilitates comparisons across various companies, and aids in assessing the influence of significant external events on stock valuations.


## Q1: How do stock prices change over time based on basic economic metrics


### Introduction

To answer the question of how stock prices change over time, the daily price movement and volume will be visualized. Looking at price changes temporally will provide insights into past trends in the stock market. The stock market is cyclical, and thus finding patterns in the past data will allow for insights into future movements of the stock market. This is benefical because it can lead to knowledge of when a stock price will rise. The interest in this question is based on team interest in investing and making low-risk financial decisions. 
 
``` {python}
# Step 1: Exploratory Data Analysis (EDA)
df = stocks.copy()

# Convert the date column to datetime format
df['date'] = pd.to_datetime(df['date'])

# Summary Statistics
company_stats = df.groupby('stock_symbol').agg({'open': ['mean', 'median', 'min', 'max', 'std'], 'volume': ['mean', 'median', 'min', 'max', 'std']})
print("Summary Statistics:")
print(company_stats)






```

### Approach

To begin the analysis of question one, the data is first summarized for basic statistics such as mean, median, standard deviation for both price variation and trading volume. This allows for a basic understanding of the distribution of the data and how metrics such as outliers influence the spread of the data. Once a basic understanding of the data is formed, the data is then visualized. 

One step that is typically used for raw, uncleaned data is filtering. This allows for the data to be manipulated to ensure a normal distribution (or other distribution required by the ML model). In the case of this analysis, filtering and cleaning is not needed because the data is already in a form that can be visualized easily. 

Finally, the data is visualized in two plots, a candlestick plot and a line plot. The candlestick plot is a line plot where each data point is a bar that shows the open, close, high, and low prices. The size of the bar represents the volume of stocks traded in that day. The bars are then connected by a line and when looking at the entire time frame, trends can be seen. The line plot will be used to show the closing prices over time. These two plots will be plotly objects, and thus can be manipuated and zoomed in on to see trends both globally and regionally over the time period. 

``` {python}
# Step 2: Data Wrangling
# Handle missing values(No missing values)


```

### Analysis



``` {python}

# Initialize an empty list to store candlestick traces for all companies
candlestick_traces = []

# Loop through each company and create a candlestick trace
for company in stocks['stock_symbol'].unique():
    df_company = stocks[stocks['stock_symbol'] == company]
    candlestick_trace = go.Candlestick(x=df_company['date'],
                                       open=df_company['open'],
                                       high=df_company['high'],
                                       low=df_company['low'],
                                       close=df_company['close'],
                                       name=f"{company} Candlestick")
    candlestick_traces.append(candlestick_trace)

# Create the figure
fig = go.Figure(data=candlestick_traces)

# Customize the layout
fig.update_layout(title='Stock Prices of Big Tech Stocks (2010 - 2022)<br><sup>Kaggle via Yahoo Finance | Tidy Tuesday 2023',
                  xaxis_title='Date',
                  yaxis_title='Price',
                  xaxis_rangeslider_visible=False,
                  height=600,
                  width=1000)

# Show the figure
fig.show()













```


``` {python}

stocks = companies['stock_symbol'].values.tolist()
# Creating a DataFrame to hold all the stock data
# For simplicity, let's generate some random closing prices
all_stock_data = df

# Create a Plotly figure
fig = go.Figure()

# Add a line for each stock
for stock in stocks:
    stock_data = df[df['stock_symbol'] == stock]
    fig.add_trace(go.Scatter(x=stock_data['date'], y=stock_data['close'], mode='lines', name=stock))

# Customize the layout
fig.update_layout(
    title='Stock Close Prices Over Time',
    xaxis_title='Date',
    yaxis_title='Close Price',
    height=400
)

# Show the figure
fig.show()
```




``` {python}
# Calculate average volume traded for each stock symbol
avg_volume = df.groupby('stock_symbol')['volume'].mean().sort_values()

# Create a bar trace
bar_trace = go.Bar(
    x=avg_volume.index,  # Stock symbols
    y=avg_volume.values,  # Average volume
    marker_color='skyblue'
)

# Create a layout
layout = go.Layout(
    title='Average Volume Traded for Each Stock Symbol',
    xaxis=dict(title='Stock Symbol'),
    yaxis=dict(title='Average Volume (Shares Traded)'),
    xaxis_tickangle=-45,
    margin=dict(l=40, r=40, t=60, b=20)
)

# Create a figure
fig = go.Figure(data=[bar_trace], layout=layout)

# Show the figure
fig.show()

```

### Discussion

The findings from data preprocessing and visualization reveals multiple insights. First, beyond cyclical fluxations, the price of every stock has increased since the initial 2010 open. Additionally, not all companies existed in 2010 and thus it can be seen that some stocks don't appear until after 2010. Another valuable insight found was the large increase in growth of a majority of the companies in 2018. If this trend is to continue, it is beneficial to invest in the market now, though it would be wise to view other companies that have experienced exponential growth and review the times before prices settled to a lower value, the dot com boom of the early 2000s would be a good case study. Finally, the crash caused by the COVID-19 pandemic is clearly visible across all the companies, when in the March of 2020, stock prices plummetted.

## Q2  Backwards verification: if we invested x amount of dollars in 2010, how much would it be worth in 2022, when would be a good/bad time to pull investment out of the market.


### Introduction
``` {python}
#| label: Data-Analysis-Q2

# Load the CSV files
stocks = pd.read_csv('data/big_tech_stock_prices.csv')
companies = pd.read_csv('data/big_tech_companies.csv')
# Copy the DataFrames to avoid modifying the original data
df_stocks = stocks.copy()
df_companies = companies.copy()
# Now you can proceed with your groupby aggregation
investment_stats = df_stocks.groupby('stock_symbol').agg({
    'open': ['mean', 'median', 'min', 'max', 'std'],
    'high': ['mean', 'median', 'min', 'max', 'std'],
    'low': ['mean', 'median', 'min', 'max', 'std'],
    'close': ['mean', 'median', 'min', 'max', 'std'],
    'adj_close': ['mean', 'median', 'min', 'max', 'std'],
    'volume': ['mean', 'median', 'min', 'max', 'std']
})
print("Summary Statistics:")
print(investment_stats)

```

### Approach
``` {python}
#| label: Data-Wrangling-Q2

# Handle missing values(No missing values)
print("Null Values from Stocks dataset", stocks.isnull().sum())
print("Null Values from companies dataset", companies.isnull().sum())

# Outlier Detection and Treatment
# Calculate the Z-score for the 'adj_close' column
df_stocks['z_score'] = stats.zscore(df_stocks['adj_close'])
# Remove outliers beyond 3 standard deviations
df_stocks = df_stocks[df_stocks['z_score'].abs() <= 3]

```

### Analysis
```{python}
#| label: Stock-Close-Prices-Over-Time
stocks = companies['stock_symbol'].values.tolist()

# Creating a DataFrame to hold all the stock data
all_stock_data = df_stocks

# Create a Plotly figure
fig = go.Figure()

# Add a line for each stock
for stock in stocks:
    stock_data = df_stocks[df_stocks['stock_symbol'] == stock]
    fig.add_trace(go.Scatter(x=stock_data['date'], y=stock_data['close'], mode='lines', name=stock))

# Customize the layout
fig.update_layout(
    title='Stock Close Prices Over Time',
    xaxis_title='Date',
    yaxis_title='Close Price',
    height=800
)

# Show the figure
fig.show()
```

```{python}
#| label: Normalized-Stock-Close-Prices
start_date = "2010-01-01"
filtered_data = all_stock_data[all_stock_data['date'] >= start_date]

# Normalize each stock's prices to start from a base (e.g., 100)
base = 10
for stock in stocks:
    initial_price = filtered_data[filtered_data['stock_symbol'] == stock].iloc[0]['close']
    filtered_data.loc[filtered_data['stock_symbol'] == stock, 'Normalized Close'] = base * (filtered_data['close'] / initial_price)

# Create a Plotly figure
fig = go.Figure()

# Add a line for each stock's normalized close prices
for stock in stocks:
    stock_data = filtered_data[filtered_data['stock_symbol'] == stock]
    fig.add_trace(go.Scatter(x=stock_data['date'], y=stock_data['Normalized Close'], mode='lines', name=stock))

# Customize the layout
fig.update_layout(
    title='Normalized Stock Close Prices Over Time',
    xaxis_title='Date',
    yaxis_title='Normalized Close Price',
    height=600
)

# Show the figure
fig.show()

```

To answer the question "when would be a good/bad time to pull investment out of the market? " we rely on a common trading strategy based on moving averages:

The 50-day moving average (50DMA) is often used as a short-term trend indicator. It’s more sensitive to price changes in the recent past.

The 200-day moving average (200DMA) is commonly used as a long-term trend indicator. It’s less sensitive to daily price fluctuations and more indicative of a longer-term trend.

When the 50DMA crosses above the 200DMA, it's often referred to as a "golden cross," which some traders interpret as a bullish signal suggesting that the price might increase, potentially a good time to buy.

Conversely, when the 50DMA crosses below the 200DMA, it's known as a "death cross," which is considered by some traders to be a bearish signal, indicating that the price might drop, and it could be a good time to sell.

``` {python}
#| label: Data-Visualization-Q2-Part2

df_AAPL = df_stocks[df_stocks['stock_symbol'] == 'AAPL']

start_date = "2013-01-01"
df_AAPL = df_AAPL[df_AAPL['date'] >= start_date]

# Calculate 200DMA and 50DMA
df_AAPL['200DMA'] = df_AAPL['close'].rolling(window=200).mean()
df_AAPL['50DMA'] = df_AAPL['close'].rolling(window=50).mean()

# Creating the candlestick chart
fig = go.Figure()

# Add Candlestick trace
fig.add_trace(go.Candlestick(x=df_AAPL['date'],
                open=df_AAPL['open'], high=df_AAPL['high'],
                low=df_AAPL['low'], close=df_AAPL['close'],
                name='Candlestick'))

# Add 200DMA Line trace
fig.add_trace(go.Scatter(x=df_AAPL['date'], y=df_AAPL['200DMA'],
                         mode='lines', name='200DMA',
                         line=dict(color='blue', width=2)))

# Add 50DMA Line trace
fig.add_trace(go.Scatter(x=df_AAPL['date'], y=df_AAPL['50DMA'],
                         mode='lines', name='50DMA',
                         line=dict(color='red', width=2)))

# Customize the layout
fig.update_layout(title='Stock Price with 200DMA and 50DMA',
                  xaxis_title='Date',
                  yaxis_title='Price',
                  xaxis_rangeslider_visible=False,  # Hides the range slider
                  height=600)

# Show the figure
fig.show()
```

### Discussion (move text from above down here)