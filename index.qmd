---
title: "Big Tech Stock Prices"
subtitle: "Analyzing Big Tech stock prices from 2010 to 2022"
author: "Tech Titans"
format: html
editor: visual
jupyter: python3
---

## Abstract

Add project abstract here.



```{python}
#| label: load-pkgs
#| message: false

# Importing the required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go


# Loading Data
stocks = pd.read_csv('data/big_tech_stock_prices.csv')
companies = pd.read_csv('data/big_tech_companies.csv')


```




## Q1: How do stock prices change over time, looking at the basic information like open, close, high, low etc.**


### EDA
``` {python}
# Step 1: Exploratory Data Analysis (EDA)
df = stocks.copy()

# Convert the date column to datetime format
df['date'] = pd.to_datetime(df['date'])

# Summary Statistics
company_stats = df.groupby('stock_symbol').agg({'open': ['mean', 'median', 'min', 'max', 'std'], 'volume': ['mean', 'median', 'min', 'max', 'std']})
print("Summary Statistics:")
print(company_stats)






```

### Data Wrangling
``` {python}
# Step 2: Data Wrangling
# Handle missing values(No missing values)


```

### Data Visualization 



``` {python}

# Initialize an empty list to store candlestick traces for all companies
candlestick_traces = []

# Loop through each company and create a candlestick trace
for company in stocks['stock_symbol'].unique():
    df_company = stocks[stocks['stock_symbol'] == company]
    candlestick_trace = go.Candlestick(x=df_company['date'],
                                       open=df_company['open'],
                                       high=df_company['high'],
                                       low=df_company['low'],
                                       close=df_company['close'],
                                       name=f"{company} Candlestick")
    candlestick_traces.append(candlestick_trace)

# Create the figure
fig = go.Figure(data=candlestick_traces)

# Customize the layout
fig.update_layout(title='Candlestick Chart for 14 Companies',
                  xaxis_title='Date',
                  yaxis_title='Price',
                  xaxis_rangeslider_visible=False,
                  height=600,
                  width=1000)

# Show the figure
fig.show()

```


Closing Prices Over Time for Different Companies
``` {python}

stocks = companies['stock_symbol'].values.tolist()
# Creating a DataFrame to hold all the stock data
# For simplicity, let's generate some random closing prices
all_stock_data = df

# Create a Plotly figure
fig = go.Figure()

# Add a line for each stock
for stock in stocks:
    stock_data = df[df['stock_symbol'] == stock]
    fig.add_trace(go.Scatter(x=stock_data['date'], y=stock_data['close'], mode='lines', name=stock))

# Customize the layout
fig.update_layout(
    title='Stock Close Prices Over Time',
    xaxis_title='Date',
    yaxis_title='Close Price',
    height=400
)

# Show the figure
fig.show()
```



Volume Analysis using Bar Plot
``` {python}
# Calculate average volume traded for each stock symbol
avg_volume = df.groupby('stock_symbol')['volume'].mean().sort_values()

# Create a bar trace
bar_trace = go.Bar(
    x=avg_volume.index,  # Stock symbols
    y=avg_volume.values,  # Average volume
    marker_color='skyblue'
)

# Create a layout
layout = go.Layout(
    title='Average Volume Traded for Each Stock Symbol',
    xaxis=dict(title='Stock Symbol'),
    yaxis=dict(title='Average Volume (Shares Traded)'),
    xaxis_tickangle=-45,
    margin=dict(l=40, r=40, t=60, b=20)
)

# Create a figure
fig = go.Figure(data=[bar_trace], layout=layout)

# Show the figure
fig.show()

```






## Q2

### EDA
``` {python}

# Load the CSV files
stocks = pd.read_csv('data/big_tech_stock_prices.csv')
companies = pd.read_csv('data/big_tech_companies.csv')

# Copy the DataFrames to avoid modifying the original data
df_stocks = stocks.copy()
df_companies = companies.copy()

# Now you can proceed with your groupby aggregation
investment_stats = df_stocks.groupby('stock_symbol').agg({
    'open': ['mean', 'median', 'min', 'max', 'std'],
    'high': ['mean', 'median', 'min', 'max', 'std'],
    'low': ['mean', 'median', 'min', 'max', 'std'],
    'close': ['mean', 'median', 'min', 'max', 'std'],
    'adj_close': ['mean', 'median', 'min', 'max', 'std'],
    'volume': ['mean', 'median', 'min', 'max', 'std']
})

print("Summary Statistics:")
print(investment_stats)


```

### Data Wrangling
``` {python}

# Step 2: Data Wrangling
# Handle missing values(No missing values)
print("Null Values from Stocks dataset", stocks.isnull().sum())
print("Null Values from companies dataset", companies.isnull().sum())


```
### Data Visualization 

``` {python}


```